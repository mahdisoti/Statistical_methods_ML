# -*- coding: utf-8 -*-
"""forest_covertype.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19HC3XkX2EdF9SF3f4fkp2XxLu7fTE4xb
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
import random

#threshold comparison to classify data

def stump_classify(data_matrix, dim, splitvalue, splitineq): 
    filter_array = np.ones((np.shape(data_matrix)[0],1))
    if splitineq == 'below':
       filter_array[data_matrix[:,dim] <= splitvalue] = -1
    else:
       filter_array[data_matrix[:,dim] > splitvalue] = -1
    return filter_array

#finding the best decision stump for our dataset

def decision_stump(data_array, labelset, D): 
    data_matrix = np.mat(data_array)
    labelset = np.mat(labelset).T
    row,col_len = np.shape(data_matrix)
    iterations = 25
    stumps = {}
    best_class = np.ones((row,1))
    min_error = np.inf
    for i in range(col_len):
        minvalue = data_matrix[:,i].min()
        maxvalue = data_matrix[:,i].max()
        step_size = (maxvalue - minvalue)/iterations
        for j in range(0, iterations):
            for inequal in ['below', 'above']:
                splitvalue = (minvalue + j * step_size)
                prediction_values = stump_classify(data_matrix,i,splitvalue,inequal)
                error_array = np.ones((row,1))
                error_array[prediction_values == labelset] = 0
                weighted_error = D.T * error_array

                if weighted_error < min_error:
                   min_error = weighted_error
                   best_class = prediction_values.copy()
                   stumps['dimension'] = i
                   stumps['split'] = splitvalue
                   stumps['ineq'] = inequal
                  
    return stumps,min_error,best_class

#based on the decision_stump we build, we start implementing the full AdaBoost

def adaboost_training(data_array,labelset,n_iterations= 40):
    weak_learners = []
    row_len = np.shape(data_array)[0]
    D = np.mat(np.ones((row_len,1))/row_len)
    agg_class_est = np.mat(np.zeros((row_len,1)))
    for i in range(n_iterations):
        stumps,error,class_est = decision_stump(data_array, labelset, D)
        alpha = float(0.5*np.log((1.0-error)/max(error,1e-16))) 
        stumps['alpha'] = alpha
        weak_learners.append(stumps)
        expon = np.multiply(-1*alpha*np.mat(labelset).T,class_est)
        D = np.multiply(D,np.exp(expon))
        D = D/D.sum()
        agg_class_est += alpha*class_est
        
        aggErrors = np.multiply(np.sign(agg_class_est) !=
                    np.mat(labelset).T,np.ones((row_len,1)))
        errorRate = aggErrors.sum()/row_len
        

        if errorRate == 0.0: break
    return weak_learners,agg_class_est

#we have an array of weak leaners + alpha value for each classifier. now we just need to take the train of weak classifiers from the training function and
#apply these to an instance

def adaboost_classifier(classification_data,classifier_array): 
    data_matrix = np.mat(classification_data) 
    row_len = np.shape(data_matrix)[0] 
    agg_class_est = np.mat(np.zeros((row_len,1))) 
    for i in range(len(classifier_array)):
        class_est = stump_classify(data_matrix,classifier_array[i]['dimension'],\
                                classifier_array[i]['split'],\
                                classifier_array[i]['ineq'])
        agg_class_est += classifier_array[i]['alpha']*class_est
        
    return (agg_class_est)

#test_train split based on the required parameters.

def split_train_test(df,test_size,label_col,random_state=50):

    random.seed(random_state)
    
    
    label_col = str(label_col)
    dat_len  = len(df)
    X= df.drop(columns=label_col)
    Y = df[label_col]
  
    
    
    if isinstance(test_size,float):
        test_size = round(test_size*dat_len)
        
    indices = list(data.index)
    test_indices = random.sample(population=indices, k=test_size)
    
    X_train = X.drop(test_indices)
    x_test  = X.loc[test_indices]
   
    Y_train= Y.drop(test_indices)
    y_test = Y.loc[test_indices]
   
    
    return X_train.sample(frac=1,random_state=random_state),x_test,Y_train.sample(frac=1,random_state=random_state),y_test

#since we have 7 classes in the dataset, we need to extent our solution to multi class. this function implements multi-class
#external cross-validation.

def multi_class_adaboost(data,k_folds,T_rounds,labelset,random_state):
    
    random.seed(random_state)
    
    X_train,x_test,Y_train,y_test = split_train_test(data,test_size=0.2,label_col=labelset,random_state=random_state)
    indices = np.array_split(list(X_train.index),k_folds)

    Cv_test_acc = np.mat(np.ones(shape=(len(T_rounds),k_folds)))
    Cv_train_acc = np.mat(np.ones(shape=(len(T_rounds),k_folds)))

    for T in T_rounds:
        for k in range(k_folds):
            train_preds= np.mat(np.ones(shape=(np.shape(X_train.drop(indices[k]))[0],len(np.unique(data[labelset])))))
            test_preds = np.mat(np.ones(shape=(np.shape(indices[k])[0],len(np.unique(data[labelset])))))
            for classes in range(len(np.unique(data[labelset]))):
                model,pred = adaboost_training(X_train.drop(indices[k]),np.where(Y_train.drop(indices[k])==classes+1,1,-1),T)
                train_preds[:,classes]=np.multiply(train_preds[:,classes],pred)
                test_est = adaboost_classifier(X_train.loc[indices[k]],model)
                test_preds[:,classes] = np.multiply(test_preds[:,classes],test_est)

            train_predictions = np.argmax(train_preds,axis=1)+1
            training_error =np.where(train_predictions!=np.mat(Y_train.drop(indices[k])).T,1,0).sum()
            Cv_train_acc[T_rounds.index(T),k]=1-(training_error/len(train_predictions))
            test_prediction = np.argmax(test_preds,axis=1)+1
            test_error = np.where(test_prediction!=np.mat(Y_train.loc[indices[k]]).T,1,0).sum()
            Cv_test_acc[T_rounds.index(T),k]=1-(test_error/len(test_prediction))
        print( 'Cv for',T,'rounds is completed')
    
    return(Cv_train_acc,Cv_test_acc)

data = pd.read_csv('covtype.csv')
data = data.sample(frac = 0.020)
forest = data.copy()

data.describe()

forest.info()

figure(figsize=(10, 6), dpi=60)
sns.countplot(x="Cover_Type", data=forest)

forest.isna().sum()

cv_train,cv_test = multi_class_adaboost(forest,k_folds=5,T_rounds=[50,150,250,350,450],
                               labelset='Cover_Type',random_state=50)

np.mean(cv_test,axis=1)

np.mean(cv_train,axis=1)

adaboost_round = 150

X_train,x_test,Y_train,y_test = split_train_test(data,test_size=0.2,label_col='Cover_Type',random_state=50)
train_preds= np.mat(np.ones(shape=(np.shape(X_train)[0],len(np.unique(data['Cover_Type'])))))
test_preds =  np.mat(np.ones(shape=(np.shape(x_test)[0],len(np.unique(data['Cover_Type'])))))
for classes in range(len(np.unique(data['Cover_Type']))): # one VS Rest classifier
    model,pred = adaboost_training(X_train,np.mat(np.where(Y_train==int(classes)+1,1,-1)),adaboost_round)
    train_preds[:,classes]=np.multiply(train_preds[:,classes],pred)
    test_est = adaboost_classifier(x_test,model)
    test_preds[:,classes]=np.multiply(test_preds[:,classes],test_est)

train_predictions = np.argmax(train_preds,axis=1)+1 # because indexing starts from 0
training_error = np.where(train_predictions != np.mat(Y_train).T,1,0).sum()
test_prediction = np.argmax(test_preds,axis=1)+1
test_error = np.where(test_prediction != np.mat(y_test).T,1,0).sum()
print('test accuracy:',1-(test_error/len(x_test)))
print('training accuracy:',1-(training_error/len(X_train)))

cv_test

np.mean(cv_test,axis=1)-np.std(cv_test,axis=1)

model # decision_stumps

train_score_mean = np.mean(np.array(cv_train),axis=1)
train_score_std = np.std(np.array(cv_train),axis=1)
test_score_mean = np.mean(np.array(cv_test),axis=1)
test_score_std = np.std(np.array(cv_test),axis=1)
T_rounds = np.array([50,150,250,350,450])
plt.figure(figsize=(12, 8), dpi=80)
plt.title('Adaboost vs number of rounds')
plt.grid()
plt.fill_between(T_rounds, train_score_mean - train_score_std,
                 train_score_mean + train_score_std, alpha=0.1,
                 color="r")
plt.fill_between(T_rounds, test_score_mean - test_score_std,
                 test_score_mean + test_score_std, alpha=0.1, color="g")
plt.plot(T_rounds, train_score_mean, 'o-', color="r",
         label="Training score")
plt.plot(T_rounds, test_score_mean, 'o-', color="g",
         label="CV accuracy")
plt.legend()
plt.xlabel('Number of Rounds')
plt.ylabel('Accuracy')